{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Anaylsis Project\n",
    "## Dan Luoma\n",
    "\n",
    "A Python script for analyzing the previous 10 days performance of selected range of stocks and ranking them using OBV analysis. <br> With the predictions of this script I intend to invest in the top three performing stocks according to their OBV ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "yfinance uses Yahoo Finance API and imports stocks to be analyzed. <br>get-all-tickers uses yfinance to filter the available stock information to obtain the stocks we are interested in analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install yfinance\n",
    "!pip install get-all-tickers\n",
    "import yfinance as yf, pandas as pd, shutil, os, time, glob, smtplib, ssl\n",
    "from get_all_tickers import get_tickers as gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the stocks we are interested in analyzing with a minimum market cap specified\n",
    "tickers = gt.get_tickers_filtered(mktcap_min=200)\n",
    "# Print the number of stocks imported to tickers\n",
    "print(\"The amount of stocks chosen to observe: \" + str(len(tickers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stock File Creation\n",
    "\n",
    "Deletes the previous days stock information, recreates the folder, and begins creating csv files for all stocks being analyzed. <br>The number of stocks being analyzed has been limited to 1800 to avoid running into import issues with yfinance. <br>The path C:/Users/dluom will need to be changed to correspond to your own file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These two lines remove the Stocks folder and then recreate it in order to remove old stocks.\n",
    "shutil.rmtree(\"C:/Users/dluom/Daily_Stock_Report/Stocks/\")\n",
    "os.mkdir(\"C:/Users/dluom/Daily_Stock_Report/Stocks/\")\n",
    "# Holds the amount of API calls we executed\n",
    "Amount_of_API_Calls = 0\n",
    "# This while loop is reponsible for storing the historical data for each ticker in our list.\n",
    "Stock_Failure = 0  # Used to make sure we don't waste too many API calls on one Stock ticker that could be having issues\n",
    "Stocks_Not_Imported = 0\n",
    "# Used to iterate through our list of tickers\n",
    "i=0\n",
    "while (i < len(tickers)) and (Amount_of_API_Calls < 1800):\n",
    "    try:\n",
    "        stock = tickers[i]  # Gets the current stock ticker\n",
    "        temp = yf.Ticker(str(stock))\n",
    "        Hist_data = temp.history(period=\"max\")  # Tells yfinance what kind of data we want about this stock (In this example, all of the historical data)\n",
    "        Hist_data.to_csv(\"C:/Users/dluom/Daily_Stock_Report/Stocks/\"+stock+\".csv\")  # Saves the historical data in csv format for further processing later\n",
    "        time.sleep(2)  # Pauses the loop for two seconds so we don't cause issues with Yahoo Finance's backend operations\n",
    "        Amount_of_API_Calls += 1 \n",
    "        Stock_Failure = 0\n",
    "        i += 1  # Iteration to the next ticker\n",
    "    except ValueError:\n",
    "        print(\"Yahoo Finance Backend Error, Attempting to Fix\")  # An error occured on Yahoo Finance's backend. We will attempt to retreive the data again\n",
    "        if Stock_Failure > 5:  # Move on to the next ticker if the current ticker fails more than 5 times\n",
    "            i+=1\n",
    "            Stocks_Not_Imported += 1\n",
    "        Amount_of_API_Calls += 1\n",
    "        Stock_Failure += 1\n",
    "print(\"The amount of stocks we successfully imported: \" + str(i - Stocks_Not_Imported))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBV Analysis\n",
    "\n",
    "Performs the OBV analysis for each stock selected. Obtains an OBV score, places them in a seperate csv file, and orders them from greatest to least. This csv file is then saved to the file created in the previous section.<br>OBV analyzis if a stock price has increased or decreased from one day to the next, compares the volume of the stock traded, and assigns it a value. For more information please see <a>href=\"https://www.investopedia.com/terms/o/onbalancevolume.asp\">this link.</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = (glob.glob(\"C:/Users/dluom/Daily_Stock_Report/Stocks/*.csv\")) # Creates a list of all csv filenames in the stocks folder\n",
    "new_data = [] #  This will be a 2D array to hold our stock name and OBV score\n",
    "interval = 0  # Used for iteration\n",
    "while interval < len(list_files):\n",
    "    print(interval)\n",
    "    Data = pd.read_csv(list_files[interval]).tail(10)  # Gets the last 10 days of trading for the current stock in iteration\n",
    "    pos_move = []  # List of days that the stock price increased\n",
    "    neg_move = []  # List of days that the stock price increased\n",
    "    OBV_Value = 0  # Sets the initial OBV_Value to zero\n",
    "    count = 0\n",
    "    if(len(Data) < 10):\n",
    "        interval += 1\n",
    "        continue\n",
    "    while (count < 10):  # 10 because we are looking at the last 10 trading days\n",
    "        if Data.iloc[count,1] < Data.iloc[count,4]:  # True if the stock increased in price\n",
    "            pos_move.append(count)  # Add the day to the pos_move list\n",
    "        elif Data.iloc[count,1] > Data.iloc[count,4]:  # True if the stock decreased in price\n",
    "            neg_move.append(count)  # Add the day to the neg_move list\n",
    "        count += 1\n",
    "    count2 = 0\n",
    "    for i in pos_move:  # Adds the volumes of positive days to OBV_Value, divide by opening price to normalize across all stocks\n",
    "        OBV_Value = round(OBV_Value + (Data.iloc[i,5]/Data.iloc[i,1]))\n",
    "    for i in neg_move:  # Subtracts the volumes of negative days from OBV_Value, divide by opening price to normalize across all stocks\n",
    "        OBV_Value = round(OBV_Value - (Data.iloc[i,5]/Data.iloc[i,1]))\n",
    "    Stock_Name = ((os.path.basename(list_files[interval])).split(\".csv\")[0])  # Get the name of the current stock we are analyzing\n",
    "    new_data.append([Stock_Name, OBV_Value])  # Add the stock name and OBV value to the new_data list\n",
    "    interval += 1\n",
    "df = pd.DataFrame(new_data, columns = ['Stock', 'OBV_Value'])  # Creates a new dataframe from the new_data list\n",
    "df[\"Stocks_Ranked\"] = df[\"OBV_Value\"].rank(ascending = False)  # Rank the stocks by their OBV_Values\n",
    "df.sort_values(\"OBV_Value\", inplace = True, ascending = False)  # Sort the ranked stocks\n",
    "df.to_csv(\"C:/Users/dluom/Daily_Stock_Report/Stocks/OBV_Ranked.csv\", index = False)  # Save the dataframe to a csv without the index column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
